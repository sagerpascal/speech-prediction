mode: train # either train or eval
use_wandb: True

# Environment
env:
  world_size: 1 # number of GPUs to run a batch in parallel

# Mask MFCC
masking:
  position: end # end, beginning or center
  n_frames: 80 # max. number of input frames
  k_frames: 60 # number of frames to predict
  use_random_pos: False

# Dataset
data:
  config_file: datasets/vox2-original.yaml

# Training settings
train:
  batch_size: 128
  max_number_of_epochs: 1000
  early_stopping: False

# LR Scheduler
lr_scheduler:
  activate: False
  step_size: 30
  gamma: 0.5

# Optimizer
optimizer:
  type: adam
  weight_decay: 0.0001