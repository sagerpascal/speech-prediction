use_wandb: False

# Environment
env:
  world_size: 1 # number of GPUs to run a batch in parallel

# Mask MFCC
masking:
  position: end # Which frames of a sequence to predict: end (subsequent frames), beginning (previous frames) or center (frames in the center)
  n_frames: 60 # max. number of input frames
  k_frames: 25 # number of frames to predict
  window_shift: 1 # None = n_frames+k_frames
  start_idx: sliding-window # beginning (first n+k frames affected per file), random (n+k frames at random position per file), sliding-window (first n+k frames, then shift by n+k -> multiple frames per file), full = whole file
  add_metadata: False # add 2 dimensions with information about speaker and sentence

# Dataset
data:
  type: mel-spectro # mel-spectro or mfcc
  config_file: datasets/timit-original.yaml
  use_subset: False
  augmentation:
    use_augmentation: False
    pitch_and_speed:
      prob: .0
      lower: 0.7
      upper: 1.3
    resample:
      prob: .5
      lower: 0.7
      upper: 1.3
    amplification:
        prob: .75
        lower: 0.8
        upper: 1.2

# Model settings
model:
  type: gru # either unet, gru or transformer
  transformer:
    n_heads: 8
    n_encoder_layers: 6
    n_decoder_layers: 6
  unet:
    encoder_name: efficientnet-b3
    encoder_depth: 5
    decoder_channels:
      - 128
      - 256
      - 256
      - 512
      - 512
  gru:
    refeed_fac: 1  # how many times to use the output as input (i.e. predict refeed_fac times k/refeed_fac frames)
    prenet:
      use_prenet: True
      hidden_size: 1024
      dropout: 0.3
    rnn:
      hidden_size: 1024
      dropout: 0.3
      use_residual: True
    postnet:
      use_prenet: True
      hidden_size: 1024
      dropout: 0.3


# Training settings
train:
  loss: mae # either mse, mae, mae-weighted, soft-dtw-l1, soft-dtw-l2, adaptive-robust
  max_number_of_epochs: 30
  early_stopping: False
  gradient_clipping:
    use_grad_clip: True
    grad_clip_threshold: 1.
  backup_frequency: 10

# LR Scheduler
lr_scheduler:
  activate: False

# Optimizer
optimizer:
  type: adam