use_wandb: True

# Environment
env:
  world_size: 2 # number of GPUs to run a batch in parallel

# Mask MFCC
masking:
  position: end # end, beginning or center
  n_frames: 60 # max. number of input frames
  k_frames: 30 # number of frames to predict
  window_shift: 1 # None = n_frames+k_frames
  start_idx: sliding-window # beginning (first n+k frames affected per file), random (n+k frames at random position per file), sliding-window (first n+k frames, then shift by n+k -> multiple frames per file)

# Dataset
data:
  type: mel-spectro # raw, mel-spectro or mfcc
  config_file: datasets/timit-original.yaml

# Model settings
model:
  type: apc # either unet, apc or transformer
  transformer:
    n_heads: 8
    n_encoder_layers: 6
    n_decoder_layers: 6
  unet:
    encoder_name: efficientnet-b3
    encoder_depth: 5
    decoder_channels:
      - 128
      - 256
      - 256
      - 512
      - 512
  apc:
    prenet:
      use_prenet: True
      num_layers: 6
      hidden_size: 512
      dropout: 0.1
    rnn:
      hidden_size: 512
      num_layers: 5
      dropout: 0.2
      use_residual: True


# Training settings
train:
  loss: mae # either mse, mae, mae-weighted or soft-dtw
  max_number_of_epochs: 1000
  early_stopping: False
  gradient_clipping:
    use_grad_clip: True
    grad_clip_threshold: 1.
  backup_frequency: 1

# LR Scheduler
lr_scheduler:
  activate: False

# Optimizer
optimizer:
  type: adam