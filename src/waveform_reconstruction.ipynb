{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "    torchaudio.set_audio_backend(\"soundfile\")\n",
    "else:\n",
    "    torchaudio.set_audio_backend(\"sox_io\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "from audio_datasets.preprocessing import get_mel_spectro_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conf = yaml.load(open(Path('configs') / 'config.yaml'), Loader=yaml.FullLoader)\n",
    "conf_file_ds  = yaml.load(open(Path('configs') / conf['data']['config_file']), Loader=yaml.FullLoader)\n",
    "\n",
    "conf['data'] = {**conf['data'], **conf_file_ds}\n",
    "conf['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "conf['env']['world_size'] = 1\n",
    "conf['env']['use_data_parallel'] = False\n",
    "\n",
    "conf['train']['batch_size'] = 32\n",
    "conf['model']['apc']['prenet']['num_layers'] = 5\n",
    "conf['model']['apc']['rnn']['num_layers'] = 4\n",
    "\n",
    "conf['data']['augmentation']['use_augmentation'] = False\n",
    "conf['masking']['add_metadata'] = False\n",
    "conf['masking']['n_frames'] = 120\n",
    "conf['masking']['k_frames'] = 25\n",
    "conf['load_weights'] = 'treasured-deluge-60_backup'\n",
    "\n",
    "print(json.dumps(conf, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the File and Convert it to a Mel-Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_mel_spectro_transform(conf).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'D:/Projekte/temporal-speech-context/data/TIMIT/SA2.WAV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = torchaudio.load(file_path)[0]\n",
    "mel_spectro = transform(waveform)\n",
    "print(mel_spectro.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waveform\n",
    "ipd.display(ipd.Audio(waveform, rate=conf['data']['transform']['sample_rate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct Signal using Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature.inverse import mel_to_audio\n",
    "ipd.display(ipd.Audio(mel_to_audio(mel_spectro[0].numpy(), hop_length=conf['data']['transform']['hop_length'], sr=conf['data']['transform']['sample_rate'], n_fft=conf['data']['transform']['n_fft']), rate=conf['data']['transform']['sample_rate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct Signal using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import InverseMelScale, GriffinLim\n",
    "\n",
    "inverse_mel = InverseMelScale(n_stft=257, n_mels=80, sample_rate=16000, f_min=0.0, f_max=8000)\n",
    "griffin_lim = GriffinLim(n_fft=512, win_length=400, hop_length=200)\n",
    "\n",
    "ipd.display(ipd.Audio(griffin_lim(inverse_mel(mel_spectro)) , rate=conf['data']['transform']['sample_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
